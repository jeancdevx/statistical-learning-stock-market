# üìà Proyecto de Aprendizaje Estad√≠stico: Predicci√≥n NYSE

Proyecto acad√©mico de clasificaci√≥n binaria para predecir la direcci√≥n del gap overnight (Open_{t+1} > Close_t) en acciones del NYSE utilizando indicadores t√©cnicos y machine learning.

> **Universidad Privada Antenor Orrego**  
> Curso: Aprendizaje Estad√≠stico  
> Docente: Hernan Sagastegui Chigne

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [Gu√≠a de Instalaci√≥n Paso a Paso](#-gu√≠a-de-instalaci√≥n-paso-a-paso)
- [Obtenci√≥n del Dataset](#-obtenci√≥n-del-dataset)
- [Construcci√≥n del Dataset de Modelado](#-construcci√≥n-del-dataset-de-modelado)
- [Entrenamiento de Modelos](#-entrenamiento-de-modelos)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Resultados Obtenidos](#-resultados-obtenidos)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Troubleshooting](#-troubleshooting)

## üìñ Descripci√≥n del Proyecto

Este proyecto implementa un sistema completo de clasificaci√≥n binaria para predecir gaps overnight en el mercado de valores NYSE. El objetivo es determinar si el precio de apertura del d√≠a siguiente ser√° mayor que el precio de cierre del d√≠a actual: **y_{t+1} = 1[Open_{t+1} > Close_t]**.

### **¬øQu√© predecimos?**
- **Clase 0**: El precio de apertura ser√° menor o igual al cierre anterior (no hay subida overnight)
- **Clase 1**: El precio de apertura ser√° mayor al cierre anterior (subida overnight)

### **Features Utilizados**
13 indicadores t√©cnicos derivados de datos OHLCV:
- **Retornos**: ret_cc_1, ret_oo_1, ret_co_1
- **Tendencia**: sma_5, sma_10, ema_10, mom_5
- **Volatilidad**: std_5, std_10, range_rel
- **Volumen**: vol_ma_10, vol_rel
- **Calendario**: dow (d√≠a de la semana)

### **Modelos Implementados**
- **Regresi√≥n Log√≠stica** con regularizaci√≥n L2
- **Random Forest** (100 √°rboles, profundidad 10)
- **SVM-SGD** con loss log_loss

### **Protocolo de Validaci√≥n**
- Split temporal: 75% train / 10% validation / 15% test
- Walk-forward cross-validation (k=5) respetando temporalidad
- Evaluaci√≥n final en conjunto de test independiente

## üîß Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado:

- **Python 3.8 o superior** (proyecto desarrollado con Python 3.13.7)
  - Verificar: `python --version`
- **Git** para clonar el repositorio
- **PowerShell** (Windows) o Terminal (macOS/Linux)
- **Espacio en disco**: ~6 GB libres
  - 500 MB para datos crudos comprimidos
  - 3 GB para datos crudos descomprimidos
  - 2.8 GB para dataset procesado
- **RAM**: M√≠nimo 8 GB recomendado (procesa 10.4 millones de registros)

## üöÄ Gu√≠a de Instalaci√≥n Paso a Paso

### **Paso 1: Clonar el Repositorio**

Abre tu terminal y ejecuta:

```bash
git clone https://github.com/jeancdevx/statistical-learning-stock-market.git
cd statistical-learning-stock-market
```

### **Paso 2: Crear Entorno Virtual**

Es **importante** usar un entorno virtual para evitar conflictos de dependencias.

**En Windows (PowerShell)**:
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

Si obtienes error de ejecuci√≥n de scripts, ejecuta primero:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**En macOS/Linux**:
```bash
python3 -m venv venv
source venv/bin/activate
```

Deber√≠as ver `(venv)` al inicio de tu prompt indicando que el entorno est√° activo.

### **Paso 3: Instalar Dependencias**

Con el entorno virtual activado:

```bash
pip install -r requirements.txt
```

Esto instalar√°:
- `pandas==2.2.3` - Manipulaci√≥n de datos tabulares
- `numpy==2.1.3` - Operaciones num√©ricas
- `scikit-learn==1.5.2` - Algoritmos de ML y m√©tricas
- `matplotlib==3.9.2` - Visualizaciones
- `pyarrow==18.1.0` - Soporte para formato Parquet (optimizaci√≥n de carga)
- `fastapi==0.104.1` - Framework web para API REST
- `uvicorn[standard]==0.24.0` - Servidor ASGI
- `python-multipart==0.0.6` - Manejo de formularios multipart
- `pydantic==2.5.0` - Validaci√≥n de datos

**Verificar instalaci√≥n**:
```bash
pip list
```

Deber√≠as ver todas las dependencias listadas.

## üìä Obtenci√≥n del Dataset

### **Opci√≥n 1: Descarga Manual desde Stooq (Recomendada)**

El sitio de Stooq requiere interacci√≥n humana (CAPTCHA), por lo que debes descargar manualmente:

#### **1.1. Descargar el archivo**

1. Ve a: https://stooq.com/db/h/
2. Busca la secci√≥n **"U.S. stocks - daily (ASCII)"**
3. Haz clic en **"Download"** para descargar `d_us_txt.zip` (~500 MB)
4. Guarda el archivo en tu carpeta de **Descargas**

#### **1.2. Extraer en el proyecto**

**En Windows (PowerShell)**:
```powershell
# Crear directorio para datos
New-Item -ItemType Directory -Force -Path datasets\nyse

# Copiar el ZIP descargado (ajusta la ruta si es necesario)
Copy-Item $env:USERPROFILE\Downloads\d_us_txt.zip datasets\nyse\

# Extraer
Expand-Archive -Path datasets\nyse\d_us_txt.zip -DestinationPath datasets\nyse\ -Force

# Verificar
Get-ChildItem datasets\nyse\data\daily\us\
```

**En macOS/Linux**:
```bash
# Crear directorio
mkdir -p datasets/nyse

# Copiar el ZIP descargado
cp ~/Downloads/d_us_txt.zip datasets/nyse/

# Extraer
cd datasets/nyse
unzip d_us_txt.zip

# Volver a ra√≠z
cd ../..

# Verificar
ls -la datasets/nyse/data/daily/us/
```

Deber√≠as ver carpetas como:
- `nasdaq etfs/`
- `nasdaq stocks/`
- `nyse etfs/`
- `nyse stocks/` ‚Üê **Esta es la que usaremos**
- `nysemkt etfs/`
- `nysemkt stocks/`

### **Opci√≥n 2: Si Ya Tienes los Datos**

Si otro miembro del equipo ya descarg√≥ los datos, simplemente copia la carpeta `datasets/nyse/` a tu proyecto:

```bash
# Ejemplo: copiar desde un compa√±ero
cp -r /ruta/del/compa√±ero/datasets/nyse ./datasets/
```

## üî® Construcci√≥n del Dataset de Modelado

Una vez que tengas los datos crudos, debes construir el dataset de modelado con los features t√©cnicos.

### **Ejecutar el Script de Construcci√≥n**

**Con el entorno virtual activado**:

**En Windows (PowerShell)**:
```powershell
.\venv\Scripts\python.exe core/data/make_dataset.py
```

**En macOS/Linux**:
```bash
./venv/bin/python core/data/make_dataset.py
```

### **Qu√© Hace Este Script**

1. **Lee 3,649 archivos** `.txt` de la carpeta `nyse stocks/`
2. **Procesa cada ticker**:
   - Convierte fechas
   - Calcula 13 indicadores t√©cnicos
   - Construye la variable objetivo (target)
   - Aplica ventanas de warm-up
3. **Consolida** todos los tickers en un DataFrame √∫nico
4. **Divide temporalmente** en train (75%) / val (10%) / test (15%)
5. **Guarda** el resultado en `datasets/processed/dataset_modelado.csv`

### **Tiempo Estimado**
- **8-12 minutos** dependiendo de tu CPU
- Procesar√° ~3,600 archivos mostrando progreso cada 500

### **Salida Esperada**

```
============================================================
PASO 2: Construcci√≥n del Dataset de Modelado
============================================================

Archivos encontrados: 3649

Procesando tickers...
  Procesados: 500/3649 tickers...
  Procesados: 1000/3649 tickers...
  ...
  Procesados: 3649/3649 tickers...

Consolidando dataset...
‚úì Dataset consolidado: 10,374,544 registros

Realizando split temporal 75% / 10% / 15%...

============================================================
RESUMEN DEL DATASET
============================================================
Total de registros: 10,374,544
Tickers √∫nicos: 2872
Rango de fechas: 1962-01-16 a 2025-10-31

Distribuci√≥n por split:
  train: 7,779,738 (74.99%)
  val  : 1,036,951 (10.00%)
  test : 1,557,855 (15.02%)

Balance de clases (global):
  Clase 0: 5,356,127 (51.63%)
  Clase 1: 5,018,417 (48.37%)

‚úì Dataset guardado: datasets\processed\dataset_modelado.csv
  Tama√±o: 2832.9 MB

============================================================
‚úì PASO 2 COMPLETADO
============================================================
```

### **Verificar que el Dataset se Cre√≥**

```powershell
# Windows
Test-Path datasets\processed\dataset_modelado.csv

# macOS/Linux
ls -lh datasets/processed/dataset_modelado.csv
```

Deber√≠as ver un archivo de aproximadamente **2.8 GB**.

### **‚ö° Optimizaci√≥n con Parquet (Recomendado)**

Para mejorar dr√°sticamente el rendimiento de carga del dataset (de 30s a 2-3s), convierte el CSV a formato Parquet:

**Ejecutar una sola vez**:

```bash
python convert_to_parquet.py
```

**Salida esperada**:
```
üìÑ Leyendo CSV: datasets\processed\dataset_modelado.csv
   Tama√±o: 2832.86 MB
‚úì CSV cargado en 27.88 segundos
   Registros: 10,374,544

üíæ Guardando Parquet: datasets\processed\dataset_modelado.parquet
‚úì Parquet guardado en 6.49 segundos
   Tama√±o: 1210.41 MB

üöÄ Probando velocidad de carga Parquet...
‚úì Parquet cargado en 2.46 segundos

üìä Mejora de velocidad: 11.3x m√°s r√°pido
   CSV:     27.88s
   Parquet: 2.46s

üíΩ Comparaci√≥n de tama√±o:
   CSV:     2832.86 MB
   Parquet: 1210.41 MB (57.3% m√°s peque√±o)

‚úÖ Conversi√≥n completada exitosamente!
```

**Beneficios del formato Parquet**:
- ‚ö° **11.3x m√°s r√°pido**: 2.5s vs 30s de carga
- üíæ **57% m√°s peque√±o**: 1.2 GB vs 2.8 GB
- üîß **Tipos preservados**: No requiere conversi√≥n de dtypes
- üì¶ **Compresi√≥n autom√°tica**: Snappy compression
- üöÄ **Optimizado para Big Data**: Formato columnar usado en producci√≥n

El sistema detecta autom√°ticamente si existe el archivo Parquet y lo usa preferentemente. Si no existe, usa el CSV como fallback.

## üéØ Entrenamiento de Modelos

Una vez que tengas el dataset procesado (y opcionalmente convertido a Parquet), puedes entrenar los modelos.

### **Comando Principal**

**Con el entorno virtual activado**:

**En Windows (PowerShell)**:
```powershell
.\venv\Scripts\python.exe train_models.py
```

**En macOS/Linux**:
```bash
./venv/bin/python train_models.py
```

### **Opciones Disponibles**

```bash
# Ver ayuda
python train_models.py --help

# Entrenar todos los modelos (por defecto)
python train_models.py

# Entrenar solo un modelo espec√≠fico
python train_models.py --models logreg

# Entrenar dos modelos
python train_models.py --models logreg rf

# Cambiar n√∫mero de folds (por defecto: 5)
python train_models.py --k-folds 3

# Especificar dataset personalizado
python train_models.py --dataset /ruta/al/dataset.csv
```

### **Tiempo Estimado de Entrenamiento**

El proceso completo tarda aproximadamente **1 hora 40 minutos**:

| Modelo | Tiempo Estimado |
|--------|-----------------|
| Logistic Regression | ~2 minutos |
| Random Forest | ~1 hora 37 minutos |
| SVM-SGD | ~3 minutos |

**¬øPor qu√© Random Forest tarda tanto?**
- Entrena 100 √°rboles de decisi√≥n
- Walk-forward CV con k=5 folds (5 entrenamientos)
- Procesa 10.4 millones de registros
- Usa 8 n√∫cleos en paralelo (configurable en `settings.py`)

### **Salida del Entrenamiento**

Ver√°s algo como esto:

```
======================================================================
               PROYECTO: PREDICCI√ìN NYSE
          Modelado de Direcci√≥n de Precio Overnight
======================================================================

Configuraci√≥n:
  Dataset:     datasets\processed\dataset_modelado.csv
  K-folds:     5
  Modelos:     Todos
  Features:    13 indicadores t√©cnicos
  Split:       75% / 10% / 15%
  Paralelismo: 8 cores
======================================================================

============================================================
Validaci√≥n Walk-Forward: Logistic Regression (k=5)
============================================================
  Fold 1/5: acc=0.5072, bacc=0.5037, f1=0.1629, roc_auc=0.5235
  Fold 2/5: acc=0.5107, bacc=0.5006, f1=0.1273, roc_auc=0.5181
  ...

  PROMEDIO:
    Accuracy:          0.5120 ¬± 0.0050
    ROC-AUC:           0.5204 ¬± 0.0034

============================================================
Evaluaci√≥n en Test: Logistic Regression
============================================================
    Accuracy:          0.5156
    ROC-AUC:           0.5131

[... contin√∫a con Random Forest y SVM ...]

======================================================================
RESUMEN FINAL - COMPARACI√ìN DE MODELOS
======================================================================

             Modelo  Accuracy  Balanced Acc  F1-Score  ROC-AUC
      Random Forest    0.5369        0.5353    0.5026   0.5549
Logistic Regression    0.5156        0.5025    0.1082   0.5131
            SVM-SGD    0.5150        0.5027    0.1521   0.5123

üèÜ MEJOR MODELO: Random Forest
   ROC-AUC: 0.5549
   Accuracy: 0.5369

‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE
   Resultados guardados en: reports/
```

### **Archivos Generados**

Despu√©s del entrenamiento, encontrar√°s en la carpeta `reports/`:

#### **M√©tricas (`reports/metrics/`)**:
- `val_cv_summary_logreg.csv` - Resultados CV de Logistic Regression
- `test_metrics_logreg.json` - M√©tricas finales de Logistic Regression
- `val_cv_summary_rf.csv` - Resultados CV de Random Forest
- `test_metrics_rf.json` - M√©tricas finales de Random Forest
- `val_cv_summary_svm.csv` - Resultados CV de SVM-SGD
- `test_metrics_svm.json` - M√©tricas finales de SVM-SGD
- `models_comparison.csv` - Comparaci√≥n de los 3 modelos

#### **Visualizaciones (`reports/figures/`)**:
- `confusion_matrix_logreg.png` - Matriz de confusi√≥n Logistic Regression
- `confusion_matrix_rf.png` - Matriz de confusi√≥n Random Forest
- `confusion_matrix_svm.png` - Matriz de confusi√≥n SVM-SGD

#### **Modelos Guardados (`models/`)**:
- `model_logreg.pkl` - Modelo serializado Logistic Regression
- `model_rf.pkl` - Modelo serializado Random Forest
- `model_svm.pkl` - Modelo serializado SVM-SGD

## üìä Interpretaci√≥n de Resultados

### **M√©tricas de Validaci√≥n Walk-Forward**

Cada modelo genera un archivo CSV con los resultados de validaci√≥n cruzada:

**Ejemplo**: `reports/metrics/val_cv_summary_rf.csv`
```csv
fold,accuracy,balanced_accuracy,f1,roc_auc
1,0.5330,0.5312,0.4989,0.5510
2,0.5339,0.5321,0.4998,0.5519
3,0.5336,0.5318,0.4995,0.5516
4,0.5333,0.5315,0.4992,0.5513
5,0.5330,0.5312,0.4989,0.5510
```

**¬øQu√© significan las m√©tricas?**

- **Accuracy**: Porcentaje de predicciones correctas (clase 0 y 1)
  - Ejemplo: 0.5330 = 53.30% de predicciones correctas
- **Balanced Accuracy**: Promedio del recall de cada clase
  - √ötil cuando las clases est√°n balanceadas (como aqu√≠: ~51% vs ~49%)
- **F1-Score**: Media arm√≥nica de precision y recall
  - Balancea falsos positivos y falsos negativos
- **ROC-AUC**: √Årea bajo la curva ROC
  - Mide capacidad de discriminaci√≥n entre clases
  - 0.5 = aleatorio, 1.0 = perfecto
  - **0.5549** (Random Forest) indica un modelo ligeramente mejor que el azar

**Estabilidad del modelo**: La desviaci√≥n est√°ndar peque√±a entre folds indica consistencia temporal.

### **M√©tricas de Test Final**

Despu√©s del entrenamiento, cada modelo tiene un archivo JSON con resultados finales:

**Ejemplo**: `reports/metrics/test_metrics_rf.json`
```json
{
  "accuracy": 0.5369,
  "balanced_accuracy": 0.5353,
  "f1": 0.5026,
  "roc_auc": 0.5549,
  "confusion_matrix": [[440123, 317134], [404438, 396160]],
  "baseline_accuracy": 0.4861,
  "n_test": 1557855,
  "n_train": 8816689
}
```

**Interpretaci√≥n**:
- **ROC-AUC 0.5549**: El modelo es ~5.5 puntos mejor que el azar
- **Accuracy 53.69%**: Predice correctamente en m√°s de la mitad de los casos
- **F1 0.5026**: Balance razonable entre precisi√≥n y recall

**Comparaci√≥n con baseline**:
- Baseline (clase mayoritaria): 48.61%
- Random Forest: 53.69%
- **Mejora relativa**: +5.08 puntos porcentuales

### **Matrices de Confusi√≥n**

Las matrices de confusi√≥n visuales est√°n en `reports/figures/`:

**Estructura**:
```
                 Predicho
                 0        1
Verdadero  0   [TN]     [FP]
           1   [FN]     [TP]
```

**Ejemplo Random Forest**:
```
                 Predicho
                 0        1
Verdadero  0   440,123  317,134
           1   404,438  396,160
```

**Interpretaci√≥n**:
- **True Negatives (TN)**: 440,123 casos donde predijo 0 correctamente
- **False Positives (FP)**: 317,134 casos donde predijo 1 incorrectamente
- **False Negatives (FN)**: 404,438 casos donde predijo 0 incorrectamente
- **True Positives (TP)**: 396,160 casos donde predijo 1 correctamente

**Tasa de Aciertos por Clase**:
- Clase 0 (bajadas): 440,123 / (440,123 + 317,134) = 58.1%
- Clase 1 (subidas): 396,160 / (404,438 + 396,160) = 49.5%

**Conclusi√≥n**: El modelo es mejor prediciendo bajadas que subidas.

### **Comparaci√≥n de Modelos**

El archivo `reports/metrics/models_comparison.csv` consolida todos los resultados:

```csv
Modelo,Accuracy,Balanced Acc,F1-Score,ROC-AUC
Random Forest,0.5369,0.5353,0.5026,0.5549
Logistic Regression,0.5156,0.5025,0.1082,0.5131
SVM-SGD,0.5150,0.5027,0.1521,0.5123
```

**Conclusi√≥n**: 
- üèÜ **Random Forest es el ganador** con ROC-AUC de 0.5549
- LogReg y SVM-SGD tienen rendimiento similar (~0.515 en accuracy)
- Random Forest tiene mejor F1-Score (0.5026 vs ~0.13)

## üìÅ Estructura Completa del Proyecto

```
proyecto/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # üìñ Esta gu√≠a completa
‚îú‚îÄ‚îÄ requirements.txt                   # üì¶ Dependencias de Python
‚îú‚îÄ‚îÄ train_models.py                    # üöÄ CLI para entrenar modelos
‚îú‚îÄ‚îÄ verificar_dataset.py              # ‚úÖ Script de verificaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ datasets/                          # üìä Datos (no incluidos en Git)
‚îÇ   ‚îú‚îÄ‚îÄ nyse/                         # Datos crudos de Stooq
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data/daily/us/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ nyse stocks/          # 3,649 archivos .txt
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ a.us.txt
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ aa.us.txt
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ processed/                    # Datos procesados
‚îÇ       ‚îú‚îÄ‚îÄ dataset_modelado.csv      # üíæ 2.8 GB - 10.4M registros (CSV)
‚îÇ       ‚îî‚îÄ‚îÄ dataset_modelado.parquet  # ‚ö° 1.2 GB - 10.4M registros (Parquet, 11x m√°s r√°pido)
‚îÇ
‚îú‚îÄ‚îÄ core/                              # üß† C√≥digo principal
‚îÇ   ‚îú‚îÄ‚îÄ config/                       # Configuraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py               # ‚öôÔ∏è Par√°metros centralizados
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                         # Construcci√≥n de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ make_dataset.py           # üî® Genera dataset_modelado.csv
‚îú‚îÄ‚îÄ convert_to_parquet.py              # ‚ö° Convierte CSV a Parquet (opcional)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                       # Modelos y evaluaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_model.py             # üèóÔ∏è Clase base abstracta
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression.py    # üìà Implementaci√≥n LogReg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ random_forest.py          # üå≥ Implementaci√≥n RF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ svm_sgd.py                # üî∑ Implementaci√≥n SVM-SGD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_factory.py          # üè≠ Patr√≥n Factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.py             # ‚úì Walk-forward CV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py               # üìä Evaluaci√≥n en test
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/                    # Orquestaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ training_pipeline.py      # üéØ Pipeline principal
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                        # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ visualization.py          # üìâ Matrices de confusi√≥n
‚îÇ
‚îú‚îÄ‚îÄ models/                            # üíæ Modelos serializados (.pkl)
‚îÇ   ‚îú‚îÄ‚îÄ model_logreg.pkl
‚îÇ   ‚îú‚îÄ‚îÄ model_rf.pkl
‚îÇ   ‚îî‚îÄ‚îÄ model_svm.pkl
‚îÇ
‚îú‚îÄ‚îÄ reports/                           # üìã Resultados del entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                      # M√©tricas en CSV/JSON
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val_cv_summary_logreg.csv    # Validaci√≥n LogReg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_metrics_logreg.json     # Test LogReg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val_cv_summary_rf.csv        # Validaci√≥n RF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_metrics_rf.json         # Test RF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val_cv_summary_svm.csv       # Validaci√≥n SVM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_metrics_svm.json        # Test SVM
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models_comparison.csv        # üìä Comparaci√≥n final
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ figures/                      # Visualizaciones PNG
‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix_logreg.png  # Matriz LogReg
‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix_rf.png      # Matriz RF
‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix_svm.png     # Matriz SVM
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # üìö Documentaci√≥n acad√©mica
‚îÇ   ‚îú‚îÄ‚îÄ Aprendizaje Estadistico - Proyecto - Jeancarlo Morales.md
‚îÇ   ‚îî‚îÄ‚îÄ Silabo AE 2025-20 - ISIA.md
‚îÇ
‚îî‚îÄ‚îÄ app/                               # üöß Aplicaci√≥n futura
```

### **Resumen de Archivos Clave**

| Archivo | Prop√≥sito |
|---------|-----------|
| `train_models.py` | Punto de entrada CLI para entrenar modelos |
| `core/config/settings.py` | Configuraci√≥n centralizada (paths, hiperpar√°metros) |
| `core/data/make_dataset.py` | Construye dataset de 10.4M registros |
| `core/models/base_model.py` | Clase abstracta con fit/predict/save |
| `core/models/model_factory.py` | Factory para crear modelos din√°micamente |
| `core/models/validation.py` | Walk-forward validation k-fold |
| `core/models/evaluate.py` | Evaluaci√≥n final en test set |
| `core/pipelines/training_pipeline.py` | Orquestador principal del flujo |
| `reports/metrics/models_comparison.csv` | Comparaci√≥n final de modelos |

## üî¨ Detalles T√©cnicos

### **Dataset**

- **Fuente**: Stooq U.S. Daily (ASCII) - NYSE stocks
- **Per√≠odo**: 1962-01-16 a 2025-10-31 (63 a√±os de historia)
- **Tickers originales**: 3,649 archivos
- **Tickers v√°lidos**: 2,872 (filtrados por datos suficientes)
- **Registros totales**: 10,374,544
- **Tama√±o en disco**: 2.8 GB (CSV)
- **Balance de clases**: 51.63% clase 0 / 48.37% clase 1

### **Features T√©cnicos (13)**

| Feature | Descripci√≥n | F√≥rmula |
|---------|-------------|---------|
| `ret_cc_1` | Retorno close-to-close | $\log(Close_t / Close_{t-1})$ |
| `ret_oo_1` | Retorno open-to-open | $\log(Open_t / Open_{t-1})$ |
| `ret_co_1` | Retorno close-to-open | $\log(Close_t / Open_t)$ |
| `sma_5` | Media m√≥vil simple 5 d√≠as | $\frac{1}{5}\sum_{i=0}^{4} Close_{t-i}$ |
| `sma_10` | Media m√≥vil simple 10 d√≠as | $\frac{1}{10}\sum_{i=0}^{9} Close_{t-i}$ |
| `ema_10` | Media m√≥vil exponencial 10 | EMA con $\alpha = 2/(10+1)$ |
| `mom_5` | Momentum 5 d√≠as | $Close_t - Close_{t-5}$ |
| `std_5` | Volatilidad 5 d√≠as | $\sigma(Close_{t-4:t})$ |
| `std_10` | Volatilidad 10 d√≠as | $\sigma(Close_{t-9:t})$ |
| `range_rel` | Rango relativo | $(High_t - Low_t) / Close_t$ |
| `vol_ma_10` | Media m√≥vil volumen 10 | $\frac{1}{10}\sum_{i=0}^{9} Volume_{t-i}$ |
| `vol_rel` | Volumen relativo | $Volume_t / vol\_ma\_10_t$ |
| `dow` | D√≠a de la semana | 1=Lunes, 5=Viernes |

**Ventana de warm-up**: 10 d√≠as (para calcular features sin NaN)

### **Target (Variable Objetivo)**

$$y_{t+1} = \mathbb{1}[Open_{t+1} > Close_t]$$

- **Clase 0**: El precio de apertura del d√≠a siguiente es **menor o igual** que el cierre de hoy (bajada)
- **Clase 1**: El precio de apertura del d√≠a siguiente es **mayor** que el cierre de hoy (subida)

**Interpretaci√≥n**: Predecimos si el precio "saltar√°" al abrir al d√≠a siguiente.

### **Split Temporal**

| Conjunto | Proporci√≥n | Registros | Uso |
|----------|------------|-----------|-----|
| **Train** | 75% | 7,779,738 | Entrenamiento inicial |
| **Val** | 10% | 1,036,951 | Walk-forward validation |
| **Test** | 15% | 1,557,855 | Evaluaci√≥n final (UNA VEZ) |

**M√©todo**: Split temporal por ticker para preservar series temporales.

**Garant√≠a anti-leakage**: 
- StandardScaler fitteado solo en train
- Validaci√≥n walk-forward usa solo datos pasados
- Test evaluado una sola vez (no hay tuning en test)

### **Protocolo de Validaci√≥n Walk-Forward**

**k=5 folds**:

1. **Fold 1**: Train en 75% ‚Üí Eval√∫a en val[0:20%]
2. **Fold 2**: Train en 75% + val[0:20%] ‚Üí Eval√∫a en val[20:40%]
3. **Fold 3**: Train en 75% + val[0:40%] ‚Üí Eval√∫a en val[40:60%]
4. **Fold 4**: Train en 75% + val[0:60%] ‚Üí Eval√∫a en val[60:80%]
5. **Fold 5**: Train en 75% + val[0:80%] ‚Üí Eval√∫a en val[80:100%]

**Ventaja**: Simula trading real donde solo usas datos pasados para predecir el futuro.

### **Hiperpar√°metros de los Modelos**

#### **Logistic Regression**
```python
LogisticRegression(
    penalty='l2',           # Regularizaci√≥n L2
    C=1.0,                  # Inverso de lambda
    solver='lbfgs',         # Optimizador
    max_iter=1000,          # M√°ximo de iteraciones
    random_state=42,        # Reproducibilidad
    n_jobs=8                # Paralelismo
)
```

#### **Random Forest**
```python
RandomForestClassifier(
    n_estimators=100,       # 100 √°rboles
    max_depth=10,           # Profundidad m√°xima
    min_samples_split=50,   # M√≠nimo para split
    min_samples_leaf=20,    # M√≠nimo en hoja
    random_state=42,        # Reproducibilidad
    n_jobs=8                # Paralelismo
)
```

#### **SVM-SGD**
```python
SGDClassifier(
    loss='log_loss',        # Para probabilidades
    penalty='l2',           # Regularizaci√≥n L2
    alpha=0.0001,           # Lambda
    max_iter=2000,          # M√°ximo de iteraciones
    tol=1e-3,               # Tolerancia de convergencia
    random_state=42,        # Reproducibilidad
    n_jobs=8                # Paralelismo
)
```

### **M√©tricas de Evaluaci√≥n**

| M√©trica | F√≥rmula | Interpretaci√≥n |
|---------|---------|----------------|
| **Accuracy** | $\frac{TP + TN}{TP + TN + FP + FN}$ | Precisi√≥n global |
| **Balanced Accuracy** | $\frac{1}{2}\left(\frac{TP}{TP+FN} + \frac{TN}{TN+FP}\right)$ | Promedio de recall por clase |
| **F1-Score** | $2 \cdot \frac{precision \cdot recall}{precision + recall}$ | Media arm√≥nica |
| **ROC-AUC** | √Årea bajo curva ROC | Capacidad de discriminaci√≥n |

**Baseline**: Siempre predecir la clase mayoritaria (para comparar con modelo trivial).

## üêõ Soluci√≥n de Problemas

### **Error: "Module 'pandas' not found"**

**Causa**: Entorno virtual no activado o dependencias no instaladas.

**Soluci√≥n**:
```powershell
# Windows
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# macOS/Linux
source venv/bin/activate
pip install -r requirements.txt
```

### **Error: "No such file or directory: datasets/nyse/"**

**Causa**: Datos crudos no descargados o extra√≠dos incorrectamente.

**Soluci√≥n**:
1. Descarga `d_us_txt.zip` desde https://stooq.com/db/h/
2. Extrae en `datasets/nyse/`
3. Verifica con `python verificar_dataset.py`

### **Error: "No such file: datasets/processed/dataset_modelado.csv"**

**Causa**: Dataset de modelado no construido a√∫n.

**Soluci√≥n**:
```powershell
python core/data/make_dataset.py
```

### **Error: "MemoryError" durante entrenamiento**

**Causa**: RAM insuficiente para procesar 10.4M registros.

**Soluci√≥n temporal** (solo para pruebas):

Edita `train_models.py` y agrega despu√©s de cargar el dataset:
```python
# L√≠nea 45, despu√©s de cargar el dataset
df = df.sample(frac=0.1, random_state=42)  # Usar solo 10%
```

**Soluci√≥n permanente**:
- Cerrar otras aplicaciones
- Aumentar RAM virtual (swap)
- Ejecutar en m√°quina con m√°s memoria

### **Entrenamiento muy lento (Random Forest)**

**Causa**: Random Forest con 100 √°rboles y 10M+ registros es computacionalmente intensivo.

**Esto es normal**: Espera 1h 30min - 2h dependiendo de tu CPU.

**Para acelerar** (sacrificando precisi√≥n):

Edita `core/config/settings.py`:
```python
# L√≠nea 45
'n_estimators': 50,     # Reducir de 100 a 50 √°rboles
'max_depth': 8,         # Reducir profundidad
```

### **Error: "Can't execute PowerShell scripts"**

**Causa**: Pol√≠tica de ejecuci√≥n de PowerShell restringida.

**Soluci√≥n**:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### **Advertencia: "DtypeWarning" al cargar dataset**

**Causa**: Advertencia normal de pandas al inferir tipos de datos.

**No requiere acci√≥n**: Es solo una advertencia, no afecta el funcionamiento.

### **Error: "FileNotFoundError: reports/metrics/"**

**Causa**: Carpetas de salida no existen a√∫n.

**Soluci√≥n**: Los scripts las crean autom√°ticamente. Si persiste:
```powershell
# Windows
New-Item -ItemType Directory -Force -Path reports\metrics
New-Item -ItemType Directory -Force -Path reports\figures
New-Item -ItemType Directory -Force -Path models

# macOS/Linux
mkdir -p reports/metrics reports/figures models
```

## üîç Verificaci√≥n Final

Para asegurar que todo funciona correctamente:

### **1. Verificar entorno virtual**
```powershell
# Deber√≠a mostrar (venv) al inicio
# Windows
Get-Command python

# macOS/Linux
which python
```

### **2. Verificar dependencias**
```powershell
pip list | Select-String "pandas|numpy|scikit-learn|matplotlib"

# Deber√≠as ver:
# pandas       2.2.3
# numpy        2.1.3
# scikit-learn 1.5.2
# matplotlib   3.9.2
```

### **3. Verificar dataset crudo**
```powershell
python verificar_dataset.py

# Deber√≠a mostrar:
# Archivos encontrados en NYSE: 3,649
```

### **4. Verificar dataset procesado**
```powershell
# Windows
Test-Path datasets\processed\dataset_modelado.csv

# macOS/Linux
ls -lh datasets/processed/dataset_modelado.csv

# Deber√≠a mostrar: ~2.8 GB
```

### **5. Verificar modelos entrenados**
```powershell
# Windows
Get-ChildItem models\*.pkl

# macOS/Linux
ls -lh models/*.pkl

# Deber√≠as ver 3 archivos:
# model_logreg.pkl
# model_rf.pkl
# model_svm.pkl
```

### **6. Verificar resultados**
```powershell
# Windows
Get-ChildItem reports\metrics\*.csv
Get-ChildItem reports\figures\*.png

# macOS/Linux
ls -lh reports/metrics/*.csv
ls -lh reports/figures/*.png

# Deber√≠as ver:
# 4 archivos CSV (3 val + 1 comparison)
# 3 archivos JSON (test metrics)
# 3 archivos PNG (confusion matrices)
```

## üìö Referencias y Recursos

### **Dataset**
- **Stooq Database**: https://stooq.com/db/h/
- **Documentaci√≥n de formato**: https://stooq.com/db/d/

### **Bibliotecas**
- **pandas**: https://pandas.pydata.org/docs/
- **scikit-learn**: https://scikit-learn.org/stable/
- **NumPy**: https://numpy.org/doc/
- **Matplotlib**: https://matplotlib.org/stable/contents.html

### **Metodolog√≠a**
- **Walk-forward validation**: https://en.wikipedia.org/wiki/Walk_forward_analysis
- **ROC-AUC**: https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics

### **Machine Learning**
- **Logistic Regression**: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
- **Random Forest**: https://scikit-learn.org/stable/modules/ensemble.html#forest
- **SVM-SGD**: https://scikit-learn.org/stable/modules/sgd.html

### **Proyecto Acad√©mico**
- **Documento principal**: `docs/Aprendizaje Estadistico - Proyecto - Jeancarlo Morales.md`
- **S√≠labo del curso**: `docs/Silabo AE 2025-20 - ISIA.md`

## üë• Autores y Contribuciones

**Desarrollador Principal**: Jeancarlo Morales  
**Curso**: Aprendizaje Estad√≠stico 2025-20  
**Instituci√≥n**: Universidad Privada Antenor Orrego (UPAO)  
**Escuela**: Ingenier√≠a de Sistemas e Inform√°tica (ISIA)

### **Contacto**
Para dudas o problemas con el proyecto, contactar a trav√©s de:
- **Email**: [jcode2006@gmail.com]
- **GitHub**: [jeancdevx]

## üìÑ Licencia

Este proyecto es de uso **acad√©mico exclusivo**.

- ‚ùå No se permite uso comercial
- ‚úÖ Permitido para estudio y aprendizaje
- ‚úÖ Permitido compartir con compa√±eros del curso
- ‚ùå No redistribuir p√∫blicamente sin permiso

**Nota sobre datos**: El dataset de Stooq est√° sujeto a sus propios t√©rminos de uso. Consultar https://stooq.com/ para m√°s informaci√≥n.

## üìù Changelog

### **Versi√≥n 1.0** (Noviembre 2025)
- ‚úÖ Construcci√≥n del dataset (10.4M registros)
- ‚úÖ Implementaci√≥n de 3 modelos (LogReg, RF, SVM-SGD)
- ‚úÖ Pipeline de entrenamiento completo
- ‚úÖ Walk-forward validation (k=5)
- ‚úÖ Evaluaci√≥n en test set
- ‚úÖ Visualizaciones (matrices de confusi√≥n)
- ‚úÖ Documentaci√≥n acad√©mica (Secciones 5 y 6)
- ‚úÖ README completo con gu√≠a paso a paso

### **Futuras Mejoras** (Roadmap)
- üîÑ Aplicaci√≥n web interactiva (Streamlit/Dash)
- üîÑ Tuning de hiperpar√°metros con GridSearchCV
- üîÑ Modelos adicionales (XGBoost, LightGBM)
- üîÑ Feature engineering avanzado (RSI, MACD, Bollinger Bands)
- üîÑ An√°lisis de feature importance
- üîÑ Backtesting con estrategia de trading

---

**üéØ Estado del Proyecto**: ‚úÖ **COMPLETO Y FUNCIONAL**

**√öltima actualizaci√≥n**: 08 de Noviembre del 2025

**¬øDudas?** Consulta la secci√≥n de [Soluci√≥n de Problemas](#-soluci√≥n-de-problemas) o contacta al autor.

---

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub!**

